import streamlit as st
from streamlit_js_eval import get_geolocation
from streamlit_folium import st_folium
import folium
import requests
import re

from transformers import MarianMTModel, MarianTokenizer

# -------------------- Page Setup --------------------
st.set_page_config(page_title="üìç JanmaBhoomi Cultural Explorer", layout="wide")
st.title("üáÆüá≥ JanmaBhoomi ‚Äî Discover India's Local Stories")

# -------------------- State Init --------------------
if "location" not in st.session_state:
    st.session_state["location"] = None
if "city" not in st.session_state:
    st.session_state["city"] = None
if "show_map" not in st.session_state:
    st.session_state["show_map"] = False

# -------------------- Helper: Get city from lat/lon --------------------
def get_city_name(lat, lon):
    try:
        response = requests.get(
            "https://nominatim.openstreetmap.org/reverse",
            params={"format": "jsonv2", "lat": lat, "lon": lon},
            headers={"User-Agent": "StreamlitApp/1.0"}
        )
        address = response.json().get("address", {})
        return address.get("city") or address.get("town") or address.get("village") or address.get("state")
    except:
        return "Unknown"

# -------------------- Location Picker Section --------------------
st.subheader("üìç Step 1: Pick Your Location")

gps = get_geolocation()
if gps and "coords" in gps:
    lat = gps["coords"]["latitude"]
    lon = gps["coords"]["longitude"]
    if st.button("üìç Detect My City"):
        st.session_state["location"] = (lat, lon)
        st.session_state["city"] = get_city_name(lat, lon)

# Toggle Map View
col1, col2 = st.columns([1, 1])
with col1:
    if st.button("üó∫Ô∏è Show Map", disabled=st.session_state["show_map"]):
        st.session_state["show_map"] = True
with col2:
    if st.button("‚ùå Hide Map", disabled=not st.session_state["show_map"]):
        st.session_state["show_map"] = False

# Show Map if toggled
if st.session_state["show_map"]:
    default_center = st.session_state["location"] or (20.5937, 78.9629)
    m = folium.Map(location=default_center, zoom_start=6)
    if st.session_state["location"]:
        folium.Marker(st.session_state["location"], popup="Selected").add_to(m)
    map_output = st_folium(m, height=400, width=600)
    if map_output and map_output.get("last_clicked"):
        clicked_lat = map_output["last_clicked"]["lat"]
        clicked_lon = map_output["last_clicked"]["lng"]
        st.session_state["location"] = (clicked_lat, clicked_lon)
        st.session_state["city"] = get_city_name(clicked_lat, clicked_lon)

# Display selected city
if st.session_state["city"]:
    st.success(f"üèôÔ∏è Selected City: **{st.session_state['city']}**")
    auto_place = st.session_state["city"]
else:
    st.info("üìå No city selected. You can still manually enter one.")
    auto_place = ""

st.divider()

# -------------------- JanmaBhoomi Cultural Explorer --------------------

# --- Language + Place Input ---
st.subheader("üåê Step 2: Explore the Culture of a Place")
lang = st.selectbox("Choose Language", ["English", "Telugu", "Hindi"])
place = st.text_input("Enter the name of an Indian place", value=auto_place)

# --- Wikipedia Summary Fetch ---
def fetch_summary(place):
    url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{place}"
    res = requests.get(url)
    if res.status_code == 200:
        return res.json().get("extract", "No summary available.")
    return "Could not fetch summary."

def fetch_image(place):
    commons_api = "https://en.wikipedia.org/w/api.php"
    params = {
        "action": "query",
        "prop": "pageimages",
        "format": "json",
        "titles": place,
        "pithumbsize": 600
    }
    res = requests.get(commons_api, params=params).json()
    pages = res.get("query", {}).get("pages", {})
    for page_id in pages:
        return pages[page_id].get("thumbnail", {}).get("source", None)
    return None

def fetch_specific_summary(title):
    url = f"https://en.wikipedia.org/api/rest_v1/page/summary/{title}"
    res = requests.get(url)
    if res.status_code == 200:
        return res.json().get("extract", "")
    return ""

def fetch_political_significance(place):
    titles_to_try = [
        f"Politics of {place}",
        f"{place} politics",
        f"{place} (Lok Sabha constituency)",
        f"Political history of {place}",
        f"History of {place}"
    ]
    for title in titles_to_try:
        summary = fetch_specific_summary(title)
        if summary and len(summary) > 50:
            return summary
    return "No notable political information found for this place."

def fetch_economy_and_industry(place):
    titles_to_try = [
        f"Economy of {place}",
        f"{place} economy",
        f"Industries in {place}",
        f"Industrial development in {place}",
        f"{place} industrial area"
    ]
    for title in titles_to_try:
        summary = fetch_specific_summary(title)
        if summary and len(summary) > 50:
            return summary
    return "No detailed economic or industrial information found."

def detect_languages(place):
    place = place.lower()
    telugu_states = ["andhra", "telangana", "hyderabad", "visakhapatnam", "vijayawada", "warangal"]
    hindi_states = ["uttar", "madhya", "bihar", "rajasthan", "delhi", "lucknow", "patna"]
    languages = set(["English"])
    for region in telugu_states:
        if region in place:
            languages.add("Telugu")
    for region in hindi_states:
        if region in place:
            languages.add("Hindi")
    return ", ".join(sorted(languages))

def extract_proper_nouns(text):
    return list(set(re.findall(r'\b(?:[A-Z][a-z]+\s?){1,4}', text)))

# --- Translation Setup using Hugging Face Models ---
@st.cache_resource(show_spinner=False)
def load_model(lang_code):
    model_name_map = {
        "Hindi": "Helsinki-NLP/opus-mt-en-hi",
        "Telugu": "Helsinki-NLP/opus-mt-en-te"
    }
    if lang_code not in model_name_map:
        return None, None
    model_name = model_name_map[lang_code]
    tokenizer = MarianTokenizer.from_pretrained(model_name)
    model = MarianMTModel.from_pretrained(model_name)
    return tokenizer, model

def translate_text(text, lang):
    if lang == "English" or not text.strip():
        return text
    
    tokenizer, model = load_model(lang)
    if not tokenizer or not model:
        # fallback if unsupported language
        return f"[{lang[:2].upper()}] {text}"

    sentences = [s.strip() for s in text.split('.') if s.strip()]
    translated_sentences = []
    batch_size = 5
    for i in range(0, len(sentences), batch_size):
        batch = sentences[i:i+batch_size]
        inputs = tokenizer(batch, return_tensors="pt", padding=True, truncation=True)
        translated = model.generate(**inputs)
        tgt_texts = [tokenizer.decode(t, skip_special_tokens=True) for t in translated]
        translated_sentences.extend(tgt_texts)
    return ". ".join(translated_sentences)

# --- Main Display ---
if st.button("Explore"):
    if not place:
        st.warning("Please enter a place name.")
    else:
        with st.spinner("Fetching cultural info..."):
            image_url = fetch_image(place)
            if image_url:
                st.image(image_url, caption=f"Image of {place}", use_container_width=True)

            summary = fetch_summary(place)
            final_summary = translate_text(summary, lang)

            st.markdown("### üßæ Knowledge Card")
            with st.container():
                st.markdown(
                    f"""
                    <div style="border:2px solid #ccc; padding:1.5rem; border-radius:15px; background-color:#f9f9f9;">
                        <h3>{place.title()}</h3>
                        <p>{final_summary}</p>
                    </div>
                    """,
                    unsafe_allow_html=True
                )

            st.markdown("### üìö Cultural Insights")
            st.subheader("üìå What is this place famous for?")
            st.write(fetch_specific_summary(place))

            st.subheader("üó∫Ô∏è Popular Tourist Attractions")
            tourism = fetch_specific_summary(f"Tourist attractions in {place}")
            if tourism:
                proper_nouns = extract_proper_nouns(tourism)
                linked_text = tourism
                for phrase in sorted(proper_nouns, key=len, reverse=True):
                    wiki_title = phrase.strip().replace(" ", "_")
                    linked_text = linked_text.replace(phrase, f"[{phrase}](https://en.wikipedia.org/wiki/{wiki_title})", 1)
                st.markdown(linked_text, unsafe_allow_html=True)
            else:
                st.info("No tourist info found.")

            st.subheader("üèõÔ∏è Cultural or Historical Importance")
            culture = fetch_specific_summary(f"Culture of {place}")
            if not culture or len(culture) < 30:
                culture = fetch_specific_summary(f"History of {place}")
            st.write(culture)

            st.subheader("üéì Educational Institutions")
            edu_text = fetch_specific_summary(f"Education in {place}") or fetch_specific_summary(f"Colleges in {place}")
            edu_points = [pt.strip() for pt in edu_text.split('.') if len(pt.strip()) > 20]
            if edu_points:
                for pt in edu_points:
                    st.markdown(f"- {pt}.")
            else:
                st.info("No detailed educational info available.")

            st.subheader("üè≠ Economic & Industrial Information")
            economy_text = fetch_economy_and_industry(place)
            st.write(economy_text)

            st.subheader("üèõÔ∏è Political Significance")
            st.write(fetch_political_significance(place))

            st.subheader("üó£Ô∏è Languages Commonly Spoken")
            st.write(detect_languages(place))

            # --- Download Knowledge Card ---
            download_text = f"""{place.title()} - Cultural Summary ({lang})\n\n{final_summary}\n
---\nüìå Famous For:\n{fetch_specific_summary(place)}\n
üó∫Ô∏è Tourist Attractions:\n{tourism}\n
üèõÔ∏è Cultural Importance:\n{culture}\n
üéì Educational Institutions:\n{"".join("- " + p + "\n" for p in edu_points)}\n
üè≠ Economy & Industry:\n{economy_text}\n
üèõÔ∏è Political Significance:\n{fetch_political_significance(place)}\n
üó£Ô∏è Languages Spoken:\n{detect_languages(place)}\n
Source: Wikipedia/Wikimedia"""

            st.download_button(
                label="üì• Download Knowledge Card",
                data=download_text,
                file_name=f"{place}_summary.txt",
                mime="text/plain"
            )

# Footer
st.markdown("---")
st.caption("üîó Cultural data sourced from Wikipedia & Wikimedia APIs.")
